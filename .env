MAC_LLM_PORTFORWARD=https://major-legible-walrus.ngrok-free.app/v1
# MAC_LLM_PORTFORWARD = http://localhost:1234/v1
# OPENROUTER_API_KEY=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
OPENROUTER_API_KEY=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

GROQ_API_KEY=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




# LLM API Keys - Choose one of the following options:

# Option 1: Groq (Recommended - Fast & Free tier available)
# Get your API key from: https://console.groq.com/

# Option 2: OpenAI (Requires paid API key)
# Get your API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=your_openai_api_key_here

# Option 3: Anthropic Claude (Requires paid API key)
# Get your API key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Option 4: Local Ollama (Free, requires Ollama installation)
# Install Ollama from: https://ollama.ai/
# Then run: ollama pull llama3.2:3b
# USE_OLLAMA=true

# Pinecone API Key (for RAG functionality)
# Get your API key from: https://app.pinecone.io/
PINECONE_API_KEY=your_pinecone_api_key_here

# Optional: Environment configuration
ENVIRONMENT=development
DEBUG=true